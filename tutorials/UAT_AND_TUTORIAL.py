import marimo

__generated_with = "0.1.0"
app = marimo.App()


@app.cell
def _():
    import logging
    import os
    import sys
    import json
    from pathlib import Path
    from typing import Any, List, Optional
    from unittest.mock import MagicMock, patch

    # Ensure src is in path
    project_root = Path.cwd()
    if str(project_root / "src") not in sys.path:
        sys.path.append(str(project_root / "src"))

    # Matome Imports
    from domain_models.config import ProcessingConfig
    from domain_models.manifest import Chunk, SummaryNode, DocumentTree, Cluster
    from domain_models.types import DIKWLevel
    from matome.engines.raptor import RaptorEngine
    from matome.engines.semantic_chunker import JapaneseSemanticChunker
    from matome.engines.embedder import EmbeddingService
    from matome.engines.cluster import GMMClusterer
    from matome.agents.summarizer import SummarizationAgent
    from matome.utils.store import DiskChunkStore
    from matome.utils.traversal import traverse_source_chunks
    from matome.exporters.markdown import export_to_markdown
    from matome.exporters.obsidian import ObsidianCanvasExporter

    # Configure Logging
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    logger = logging.getLogger("UAT")
    return (
        Any,
        Chunk,
        Cluster,
        DIKWLevel,
        DiskChunkStore,
        DocumentTree,
        EmbeddingService,
        GMMClusterer,
        JapaneseSemanticChunker,
        List,
        MagicMock,
        ObsidianCanvasExporter,
        Optional,
        Path,
        ProcessingConfig,
        RaptorEngine,
        SummarizationAgent,
        SummaryNode,
        export_to_markdown,
        json,
        logger,
        logging,
        os,
        patch,
        project_root,
        sys,
        traverse_source_chunks,
    )


@app.cell
def _(os, logger):
    # Check for API Key
    api_key = os.environ.get("OPENROUTER_API_KEY")
    is_mock_mode = not api_key

    if is_mock_mode:
        logger.info("⚠️  OPENROUTER_API_KEY not found. Running in MOCK MODE.")
    else:
        logger.info("✅  OPENROUTER_API_KEY found. Running in REAL MODE.")
    return api_key, is_mock_mode


@app.cell
def _(MagicMock, patch, is_mock_mode, logger):
    # Mocking Utilities

    def get_mock_embeddings(texts: list[str]):
        import numpy as np
        import random
        # Return numpy array
        return np.array([[random.random() for _ in range(384)] for _ in texts])

    def mock_llm_call(*args, **kwargs):
        return "This is a mock summary generated by the UAT script."

    context_managers = []

    if is_mock_mode:
        # Mock Embeddings
        # We patch SentenceTransformer within EmbeddingService if possible, or higher level.
        # Since EmbeddingService lazy loads SentenceTransformer, patching 'sentence_transformers.SentenceTransformer' is good.

        # We create a mock model that has .encode method
        mock_model = MagicMock()
        mock_model.encode.side_effect = lambda texts, **kwargs: get_mock_embeddings(texts)

        p1 = patch("matome.engines.embedder.SentenceTransformer", return_value=mock_model)

        # Mock LLM
        # Patch the SummarizationAgent.summarize method
        p2 = patch("matome.agents.summarizer.SummarizationAgent.summarize", return_value="Mock Summary Content")

        # Also need to mock ChatOpenAI if it's instantiated
        p3 = patch("matome.agents.summarizer.ChatOpenAI", new=MagicMock())

        context_managers.extend([p1, p2, p3])
        for _cm in context_managers:
            _cm.start()

        logger.info("Mocks activated.")

    return context_managers, get_mock_embeddings, mock_llm_call


@app.cell
def _(logger, project_root):
    # Scenario 1: Quickstart (Data Loading)
    logger.info("--- Scenario 1: Quickstart ---")

    test_data_path = project_root / "test_data" / "sample.txt"
    if not test_data_path.exists():
        raise FileNotFoundError(f"Test data not found at {test_data_path}")

    with open(test_data_path, "r", encoding="utf-8") as _f:
        content = _f.read()

    logger.info(f"Loaded {len(content)} chars from {test_data_path.name}")
    return content, test_data_path


@app.cell
def _(
    DiskChunkStore,
    EmbeddingService,
    GMMClusterer,
    JapaneseSemanticChunker,
    ProcessingConfig,
    RaptorEngine,
    SummarizationAgent,
    SummaryNode,
    content,
    logger,
):
    # Initialize Engine
    # We use a temporary store for the tutorial
    store = DiskChunkStore(db_path=None) # In-memory/Temp file

    config = ProcessingConfig(
        n_clusters=2, # Using n_clusters to force GMM if applicable
        umap_n_neighbors=2,
        embedding_model="sentence-transformers/all-MiniLM-L6-v2",
        summarization_model="openai/gpt-4o-mini",
        chunk_buffer_size=10, # Small buffer for testing
    )

    # Initialize Components
    embedder = EmbeddingService(config)
    chunker = JapaneseSemanticChunker(embedder)
    clusterer = GMMClusterer()
    summarizer = SummarizationAgent(config)

    try:
        engine = RaptorEngine(
            chunker=chunker,
            embedder=embedder,
            clusterer=clusterer,
            summarizer=summarizer,
            config=config
        )
        logger.info("RaptorEngine initialized.")
    except Exception as e:
        logger.error(f"Failed to initialize RaptorEngine: {e}")
        raise

    # Run Pipeline
    logger.info("Running Raptor Pipeline (Chunking -> Embedding -> Clustering -> Summarizing)...")
    try:
        # We pass the content as a single string (or list of strings)
        tree = engine.run(content, store=store)

        root_id = tree.root_node.id if isinstance(tree.root_node, SummaryNode) else str(tree.root_node.index)
        logger.info(f"Pipeline complete. Root Node ID: {root_id}")
    except Exception as e:
        logger.error(f"Pipeline failed: {e}")
        # If pipeline fails, we still want to close store?
        store.close()
        raise
    return (
        chunker,
        clusterer,
        config,
        embedder,
        engine,
        root_id,
        store,
        summarizer,
        tree,
    )


@app.cell
def _(tree, logger):
    # Scenario 2 & 3 Verification
    logger.info("--- Verification ---")

    if not tree.root_node:
        raise ValueError("Tree has no root node")

    # Get max level from metadata if available, or just check root node level
    level = tree.metadata.get("levels", 0)
    logger.info(f"Tree Depth: {level}")

    # Basic check
    if level < 1:
        logger.warning("Tree depth is less than 1. This might be expected for very short text.")

    return level


@app.cell
def _(export_to_markdown, project_root, store, tree, logger):
    # Scenario 4: Export and Visualization
    logger.info("--- Scenario 4: Export ---")

    # Markdown Export
    md_content = export_to_markdown(tree, store)

    output_md_path = project_root / "summary_all.md"
    with open(output_md_path, "w", encoding="utf-8") as _f:
        _f.write(md_content)
    logger.info(f"Exported Markdown to {output_md_path}")

    return md_content, output_md_path


@app.cell
def _(ObsidianCanvasExporter, project_root, store, tree, logger):
    # Canvas Export
    canvas_exporter = ObsidianCanvasExporter()

    output_canvas_path = project_root / "summary_kj.canvas"

    # Use export method which writes to file
    canvas_exporter.export(tree, output_canvas_path, store)

    logger.info(f"Exported Canvas to {output_canvas_path}")
    return canvas_exporter, output_canvas_path


@app.cell
def _(context_managers, logger, store):
    # Cleanup Mocks
    store.close()
    for _cm in context_managers:
        _cm.stop()
    logger.info("Mocks deactivated.")
    logger.info("✅ UAT COMPLETE")
    return


if __name__ == "__main__":
    app.run()
