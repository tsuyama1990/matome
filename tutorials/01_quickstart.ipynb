{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 01: Quickstart (The \"Aha! Moment\")\n",
    "\n",
    "Goal: Demonstrate the instant extraction of \"Wisdom\" from a complex text and Semantic Zooming.\n",
    "\n",
    "We will:\n",
    "1.  Setup a Mock Environment (to run without API keys).\n",
    "2.  Ingest a sample text.\n",
    "3.  Run the RAPTOR engine to build a knowledge tree.\n",
    "4.  Visualize the root \"Wisdom\" node.\n",
    "5.  Zoom in to reveal \"Knowledge\" nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from collections.abc import Iterable, Iterator\n",
    "import numpy as np\n",
    "\n",
    "from domain_models.config import ProcessingConfig\n",
    "from domain_models.data_schema import DIKWLevel, NodeMetadata\n",
    "from domain_models.manifest import SummaryNode, Chunk\n",
    "from matome.engines.embedder import EmbeddingService\n",
    "from matome.engines.cluster import GMMClusterer\n",
    "from matome.engines.raptor import RaptorEngine\n",
    "from matome.engines.token_chunker import JapaneseTokenChunker\n",
    "from matome.agents.summarizer import SummarizationAgent\n",
    "from matome.agents.strategies import WisdomStrategy, KnowledgeStrategy, BaseSummaryStrategy\n",
    "from matome.utils.store import DiskChunkStore\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "logger = logging.getLogger(\"matome\")\n",
    "\n",
    "# Force Mock Mode\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = \"mock\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mock Services\n",
    "Since we want this tutorial to run instantly and without cost, we mock the Embedding Service and the Agent's response logic to simulate DIKW levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockEmbeddingService(EmbeddingService):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.dim = 384\n",
    "\n",
    "    def embed_strings(self, texts: Iterable[str]) -> Iterator[list[float]]:\n",
    "        # Return random normalized vectors\n",
    "        for _ in texts:\n",
    "            vec = np.random.rand(self.dim)\n",
    "            yield (vec / np.linalg.norm(vec)).tolist()\n",
    "\n",
    "class LevelAwareMockAgent(SummarizationAgent):\n",
    "    \"\"\"\n",
    "    A special mock agent that returns different content based on the tree level.\n",
    "    Level 2 (Root) -> Wisdom\n",
    "    Level 1 -> Knowledge\n",
    "    \"\"\"\n",
    "    def _handle_mock_mode(\n",
    "        self,\n",
    "        safe_text_str: str,\n",
    "        context: dict[str, Any] | None,\n",
    "        request_id: str,\n",
    "        strategy: Any = None,\n",
    "    ) -> SummaryNode:\n",
    "        level = context.get(\"level\", 1) if context else 1\n",
    "        \n",
    "        if level >= 2:\n",
    "            # Wisdom\n",
    "            summary = \"WISDOM: The essence of the text is that hierarchical understanding enables better decision making.\"\n",
    "            dikw = DIKWLevel.WISDOM\n",
    "        else:\n",
    "            # Knowledge\n",
    "            summary = f\"KNOWLEDGE: This section explains the mechanism of {safe_text_str[:20]}...\"\n",
    "            dikw = DIKWLevel.KNOWLEDGE\n",
    "            \n",
    "        return SummaryNode(\n",
    "            id=str(uuid.uuid4()),\n",
    "            text=summary,\n",
    "            level=level,\n",
    "            children_indices=context.get(\"children_indices\", []) if context else [],\n",
    "            metadata=NodeMetadata(dikw_level=dikw)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration & Initialization\n",
    "We configure the engine to use our mocks and GMM clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ProcessingConfig(\n",
    "    summarization_model=\"gpt-4o-mini\",\n",
    "    clustering_algorithm=\"gmm\",\n",
    "    n_clusters=2,  # Force branching to create levels\n",
    "    chunk_buffer_size=10,\n",
    ")\n",
    "\n",
    "# Clean up previous run\n",
    "db_path = Path(\"tutorials/chunks.db\")\n",
    "if db_path.exists():\n",
    "    db_path.unlink()\n",
    "\n",
    "store = DiskChunkStore(db_path)\n",
    "chunker = JapaneseTokenChunker()\n",
    "embedder = MockEmbeddingService(config)\n",
    "clusterer = GMMClusterer()\n",
    "# Inject our level-aware agent\n",
    "agent = LevelAwareMockAgent(config, strategy=WisdomStrategy())\n",
    "\n",
    "engine = RaptorEngine(chunker, embedder, clusterer, agent, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Pipeline\n",
    "We generate some dummy text and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate enough text with newlines to force chunking\n",
    "# The Japanese chunker splits on newlines if punctuation is missing\n",
    "dummy_text = \"\\n\".join([f\"Matome 2.0 is a system for semantic zooming. Part {i}\" for i in range(200)])\n",
    "\n",
    "print(\"Running RAPTOR...\")\n",
    "tree = engine.run(dummy_text, store=store)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Wisdom (The \"Aha! Moment\")\n",
    "We inspect the root node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tree.root_node\n",
    "\n",
    "if isinstance(root, Chunk):\n",
    "    print(\"Tree did not generate summaries (only 1 chunk). Try increasing text length.\")\n",
    "    print(f\"Chunk Content: {root.text[:100]}...\")\n",
    "else:\n",
    "    # Safely access metadata\n",
    "    dikw = root.metadata.dikw_level.value.upper()\n",
    "    print(f\"[{dikw}] (Level {root.level})\")\n",
    "    print(f\"Summary: {root.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Zooming\n",
    "Now we zoom in to see the child nodes (Knowledge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(root, Chunk):\n",
    "    children_map = store.get_nodes(root.children_indices)\n",
    "\n",
    "    for child_id in root.children_indices:\n",
    "        child = children_map.get(child_id)\n",
    "        if child:\n",
    "            # Determine level label\n",
    "            if isinstance(child, Chunk):\n",
    "                label = \"DATA\"\n",
    "                text = child.text[:100] + \"...\"\n",
    "            else:\n",
    "                label = child.metadata.dikw_level.value.upper()\n",
    "                text = child.text\n",
    "                \n",
    "            print(f\"\\n[{label}] (Level {child.level if hasattr(child, 'level') else 0})\")\n",
    "            print(f\"Summary: {text}\")\n",
    "        \n",
    "store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}