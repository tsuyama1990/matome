{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import Any, Iterator, cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from domain_models.config import ProcessingConfig\n",
    "from domain_models.types import DIKWLevel\n",
    "from domain_models.manifest import Chunk, SummaryNode\n",
    "from matome.agents.summarizer import SummarizationAgent\n",
    "from matome.engines.cluster import GMMClusterer\n",
    "from matome.engines.embedder import EmbeddingService\n",
    "from matome.engines.interactive_raptor import InteractiveRaptorEngine\n",
    "from matome.engines.raptor import RaptorEngine\n",
    "from matome.engines.token_chunker import JapaneseTokenChunker\n",
    "from matome.interfaces import PromptStrategy\n",
    "from matome.utils.store import DiskChunkStore\n",
    "from matome.exporters.markdown import export_to_markdown\n",
    "from matome.exporters.obsidian import ObsidianCanvasExporter\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, force=True)\n",
    "logger = logging.getLogger(\"matome.tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MOCK CLASSES ---\n",
    "\n",
    "class MockEmbeddingService(EmbeddingService):\n",
    "    \"\"\"Mock Embedder to avoid downloading heavy models.\"\"\"\n",
    "\n",
    "    def __init__(self, config: ProcessingConfig):\n",
    "        super().__init__(config)\n",
    "        self.dim = 384  # Default for all-MiniLM-L6-v2\n",
    "\n",
    "    def embed_strings(self, texts: Any) -> Iterator[list[float]]:\n",
    "        # Return random vectors\n",
    "        for _ in texts:\n",
    "            # Use seed for deterministic results\n",
    "            yield np.random.rand(self.dim).tolist()\n",
    "\n",
    "    def embed_chunks(self, chunks: Iterator[Chunk]) -> Iterator[Chunk]:\n",
    "        for chunk in chunks:\n",
    "            chunk.embedding = np.random.rand(self.dim).tolist()\n",
    "            yield chunk\n",
    "\n",
    "class MockSummarizationAgent(SummarizationAgent):\n",
    "    \"\"\"Mock Agent to return deterministic summaries based on strategy.\"\"\"\n",
    "\n",
    "    def summarize(\n",
    "        self,\n",
    "        text: str,\n",
    "        config: ProcessingConfig | None = None,\n",
    "        strategy: PromptStrategy | None = None,\n",
    "        context: dict[str, Any] | None = None,\n",
    "    ) -> str:\n",
    "        # Check context for refinement instruction\n",
    "        if context and \"instruction\" in context:\n",
    "            return f\"Refined: {context['instruction']} (Original len: {len(text)})\"\n",
    "\n",
    "        # Check strategy for DIKW level\n",
    "        level_name = \"Summary\"\n",
    "        if strategy:\n",
    "            try:\n",
    "                level_name = strategy.target_dikw_level.value.capitalize()\n",
    "            except AttributeError:\n",
    "                level_name = type(strategy).__name__\n",
    "\n",
    "        return f\"{level_name}: {text[:50]}... (Mock Generated)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SETUP & INITIALIZATION ---\n",
    "\n",
    "# Determine mode\n",
    "api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "mock_mode = not api_key or api_key == \"mock\"\n",
    "\n",
    "logger.info(f\"Running in {'MOCK' if mock_mode else 'REAL'} mode.\")\n",
    "\n",
    "# Initialize Config\n",
    "config = ProcessingConfig()\n",
    "\n",
    "# Ensure tutorials directory exists\n",
    "os.makedirs(\"tutorials\", exist_ok=True)\n",
    "\n",
    "# Initialize Components\n",
    "chunker = JapaneseTokenChunker(config)\n",
    "clusterer = GMMClusterer()\n",
    "\n",
    "if mock_mode:\n",
    "    embedder = MockEmbeddingService(config)\n",
    "    summarizer = MockSummarizationAgent(config)\n",
    "else:\n",
    "    embedder = EmbeddingService(config)\n",
    "    summarizer = SummarizationAgent(config)\n",
    "\n",
    "# Initialize Engine\n",
    "engine = RaptorEngine(chunker, embedder, clusterer, summarizer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SCENARIO 1: Quickstart (The Basics) ---\n",
    "logger.info(\"Starting SCENARIO 1: Quickstart\")\n",
    "\n",
    "# Sample text (simulating a financial document)\n",
    "SAMPLE_TEXT = \"\"\"\n",
    "ã€æŠ•è³‡å“²å­¦ã€‘\n",
    "ãƒãƒªãƒ¥ãƒ¼æŠ•è³‡ã¯ã€ä½•ã‚‰ã‹ã®ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«åˆ†æžã«ã‚ˆã‚ŠéŽå°è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹è¨¼åˆ¸ã‚’è³¼å…¥ã™ã‚‹æŠ•è³‡æ‰‹æ³•ã§ã‚ã‚‹ã€‚\n",
    "ã“ã®æ¦‚å¿µã¯ãƒ™ãƒ³ã‚¸ãƒ£ãƒŸãƒ³ãƒ»ã‚°ãƒ¬ã‚¢ãƒ ã¨ãƒ‡ãƒ“ãƒƒãƒ‰ãƒ»ãƒ‰ãƒƒãƒ‰ã«ã‚ˆã£ã¦æœ€åˆã«åºƒã‚ã‚‰ã‚ŒãŸã€‚\n",
    "ã‚¦ã‚©ãƒ¼ãƒ¬ãƒ³ãƒ»ãƒãƒ•ã‚§ãƒƒãƒˆã¯ã“ã®æˆ¦ç•¥ã®æœ€ã‚‚æœ‰åãªæ”¯æŒè€…ã®ä¸€äººã§ã‚ã‚‹ã€‚\n",
    "\n",
    "ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€‘\n",
    "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€è¡¨ç¾å­¦ç¿’ã‚’ä¼´ã†äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«åŸºã¥ãæ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã®åºƒç¯„ãªãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ä¸€éƒ¨ã§ã‚ã‚‹ã€‚\n",
    "å­¦ç¿’ã¯ã€æ•™å¸«ã‚ã‚Šã€åŠæ•™å¸«ã‚ã‚Šã€ã¾ãŸã¯æ•™å¸«ãªã—ã§è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚\n",
    "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ“ãƒªãƒ¼ãƒ•ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€æ·±å±¤å¼·åŒ–å­¦ç¿’ã€ãƒªã‚«ãƒ¬ãƒ³ãƒˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãªã©ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€éŸ³å£°èªè­˜ã€è‡ªç„¶è¨€èªžå‡¦ç†ã€æ©Ÿæ¢°ç¿»è¨³ã€ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒžãƒ†ã‚£ã‚¯ã‚¹ã€å‰µè–¬ã€åŒ»ç™‚ç”»åƒåˆ†æžã€ææ–™æ¤œæŸ»ã€ãƒœãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãªã©ã®åˆ†é‡Žã«é©ç”¨ã•ã‚Œã€äººé–“ã®å°‚é–€å®¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã«åŒ¹æ•µã—ã€å ´åˆã«ã‚ˆã£ã¦ã¯ãã‚Œã‚’è¶…ãˆã‚‹çµæžœã‚’ç”Ÿã¿å‡ºã—ã¦ã„ã‚‹ã€‚\n",
    "\n",
    "ã€å››å­£å ±ã®èª­ã¿æ–¹ã€‘\n",
    "ä¼šç¤¾å››å­£å ±ã¯ã€æ—¥æœ¬ã®å…¨ä¸Šå ´ä¼æ¥­ã®ãƒ‡ãƒ¼ã‚¿ãƒ–ãƒƒã‚¯ã§ã‚ã‚‹ã€‚\n",
    "æ¥­ç¸¾äºˆæƒ³ã€è²¡å‹™çŠ¶æ³ã€æ ªä¸»æ§‹æˆãªã©ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚\n",
    "ç‰¹ã«é‡è¦ãªã®ã¯ã€Œæ¥­ç¸¾æ¬„ã€ã§ã‚ã‚Šã€å£²ä¸Šé«˜ã‚„å–¶æ¥­åˆ©ç›Šã®æŽ¨ç§»ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ã€ä¼æ¥­ã®æˆé•·æ€§ã‚’åˆ¤æ–­ã§ãã‚‹ã€‚\n",
    "ã¾ãŸã€ã€Œææ–™æ¬„ã€ã«ã¯ã€æ–°è£½å“ã®é–‹ç™ºçŠ¶æ³ã‚„ææºè©±ãªã©ã€å°†æ¥ã®æ ªä¾¡ã«å½±éŸ¿ã‚’ä¸Žãˆã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹æƒ…å ±ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ã€‚\n",
    "PERï¼ˆæ ªä¾¡åŽç›ŠçŽ‡ï¼‰ã‚„PBRï¼ˆæ ªä¾¡ç´”è³‡ç”£å€çŽ‡ï¼‰ãªã©ã®æŒ‡æ¨™ã‚‚é‡è¦ã§ã‚ã‚‹ãŒã€ã“ã‚Œã‚‰ã¯ã‚ãã¾ã§éŽåŽ»ã®å®Ÿç¸¾ã«åŸºã¥ãã‚‚ã®ã§ã‚ã‚Šã€å°†æ¥ã®æˆé•·æ€§ã‚’åŠ å‘³ã—ã¦åˆ¤æ–­ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚\n",
    "\"\"\" * 3  # Duplicate to ensure enough content for chunking\n",
    "\n",
    "# 1. Chunking\n",
    "chunks = list(chunker.split_text(SAMPLE_TEXT, config))\n",
    "logger.info(f\"Generated {len(chunks)} chunks.\")\n",
    "\n",
    "# 2. Visualize Chunks\n",
    "print(\"--- First 5 Chunks ---\")\n",
    "for i, chunk in enumerate(chunks[:5]):\n",
    "    print(f\"Chunk {i}: {chunk.text.strip()[:50]}...\")\n",
    "\n",
    "assert len(chunks) > 0, \"Should generate chunks\"\n",
    "\n",
    "print(\"âœ… SCENARIO 1 Passed: Text ingested and chunked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SCENARIO 2: Clustering Deep Dive (The Engine) ---\n",
    "logger.info(\"Starting SCENARIO 2: Clustering Deep Dive\")\n",
    "\n",
    "# 1. Generate Embeddings\n",
    "# Note: embedder.embed_chunks yields chunks with embeddings populated\n",
    "embedded_chunks = list(embedder.embed_chunks(iter(chunks)))\n",
    "logger.info(\"Embeddings generated.\")\n",
    "\n",
    "# 2. Run Clustering\n",
    "# We manually trigger clustering to visualize it\n",
    "# GMMClusterer expects chunks with embeddings\n",
    "# Note: GMMClusterer.cluster returns (clusters, global_embeddings)\n",
    "# But wait, RaptorEngine handles this. Let's inspect GMMClusterer.\n",
    "# We can just inspect the embeddings for visualization since clustering logic is internal\n",
    "\n",
    "# Extract embeddings for visualization\n",
    "embeddings = [c.embedding for c in embedded_chunks if c.embedding]\n",
    "\n",
    "if len(embeddings) >= 2:\n",
    "    # Visualize 2D projection\n",
    "    # We use PCA for simplicity here (mocking UMAP)\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    coords = pca.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(coords[:, 0], coords[:, 1], alpha=0.5)\n",
    "    plt.title(\"Chunk Embeddings Projection (PCA)\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.grid(True)\n",
    "    # In a real notebook, this would show the plot. In headless, we save it.\n",
    "    plt.savefig(\"tutorials/clustering_visualization.png\")\n",
    "    logger.info(\"Clustering visualization saved to tutorials/clustering_visualization.png\")\n",
    "else:\n",
    "    logger.warning(\"Not enough embeddings to visualize.\")\n",
    "\n",
    "print(\"âœ… SCENARIO 2 Passed: Embeddings generated and visualized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SCENARIO 3: Full Raptor Pipeline (The \"Aha!\" Moment) ---\n",
    "logger.info(\"Starting SCENARIO 3: Full Raptor Pipeline\")\n",
    "\n",
    "# Setup temporary DB\n",
    "db_path = Path(\"tutorials/chunks.db\")\n",
    "if db_path.exists():\n",
    "    db_path.unlink()\n",
    "\n",
    "store = DiskChunkStore(db_path)\n",
    "\n",
    "# Run Engine\n",
    "try:\n",
    "    root_tree = engine.run(SAMPLE_TEXT, store)\n",
    "    logger.info(\"Raptor Engine finished successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Raptor Engine failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Validation\n",
    "root_node = root_tree.root_node\n",
    "logger.info(f\"Root Node Level: {root_node.level}\")\n",
    "\n",
    "# Export to Markdown\n",
    "md_output = export_to_markdown(root_tree, store)\n",
    "with open(\"summary_all.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md_output)\n",
    "\n",
    "logger.info(\"Exported summary to summary_all.md\")\n",
    "\n",
    "assert Path(\"summary_all.md\").exists(), \"Markdown file should exist\"\n",
    "assert len(md_output) > 0, \"Markdown content should not be empty\"\n",
    "\n",
    "print(\"âœ… SCENARIO 3 Passed: Pipeline executed and Markdown exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SCENARIO 4: KJ Method Visualization (The Output) ---\n",
    "logger.info(\"Starting SCENARIO 4: KJ Method Visualization\")\n",
    "\n",
    "exporter = ObsidianCanvasExporter(config)\n",
    "output_path = Path(\"summary_kj.canvas\")\n",
    "\n",
    "exporter.export(root_tree, output_path, store)\n",
    "\n",
    "logger.info(f\"Exported Canvas to {output_path}\")\n",
    "\n",
    "assert output_path.exists(), \"Canvas file should exist\"\n",
    "\n",
    "print(\"âœ… SCENARIO 4 Passed: Obsidian Canvas exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BONUS: Interactive Refinement & Traceability ---\n",
    "\n",
    "# Interactive Refinement\n",
    "interactive = InteractiveRaptorEngine(store, summarizer, config)\n",
    "target_node_id = root_node.id\n",
    "instruction = \"Explain like I'm 5\"\n",
    "\n",
    "refined_node = interactive.refine_node(str(target_node_id), instruction)\n",
    "\n",
    "assert refined_node.metadata.is_user_edited is True\n",
    "assert instruction in refined_node.metadata.refinement_history\n",
    "\n",
    "print(f\"Refined Node: {refined_node.text[:50]}...\")\n",
    "print(\"âœ… Interactive Refinement Verified.\")\n",
    "\n",
    "# Traceability\n",
    "source_chunks = list(interactive.get_source_chunks(str(target_node_id)))\n",
    "assert len(source_chunks) > 0\n",
    "assert isinstance(source_chunks[0], Chunk)\n",
    "\n",
    "print(f\"Traced {len(source_chunks)} source chunks.\")\n",
    "print(\"âœ… Traceability Verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ‰ All Scenarios Passed!\")\n",
    "print(f\"To explore the tree visually, run: uv run matome serve {db_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "width": "medium"
   },
   "marimo_version": "0.19.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
