{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import marimo as mo\n",
    "\n",
    "# Ensure src is in path for local execution\n",
    "src_path = str(Path.cwd() / \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Setup Logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(\"UAT\")\n",
    "\n",
    "mo.md(\n",
    "    \"\"\"\n",
    "    # Matome 2.0: User Acceptance Test & Tutorial\n",
    "\n",
    "    Welcome to the executable tutorial for **Matome 2.0**. This notebook serves two purposes:\n",
    "    1.  **Interactive Guide**: Learn how to use the system step-by-step.\n",
    "    2.  **Automated UAT**: Verify that the core engines (Batch & Interactive) are working correctly.\n",
    "\n",
    "    **Note:** If no API Key is found, we will run in **Mock Mode**.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key Handling\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\") or os.getenv(\"OPENAI_API_KEY\")\n",
    "mock_mode = False\n",
    "\n",
    "if not api_key or api_key == \"mock\":\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = \"mock\"  # Force mock mode for SummarizationAgent\n",
    "    mock_mode = True\n",
    "    print(\"âš ï¸ No API Key found (or set to 'mock'). Running in **MOCK MODE**.\")\n",
    "else:\n",
    "    print(\"âœ… API Key detected. Running in **REAL MODE**.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "from domain_models.config import ProcessingConfig\n",
    "from domain_models.manifest import Chunk, SummaryNode\n",
    "from domain_models.types import DIKWLevel\n",
    "from matome.agents.summarizer import SummarizationAgent\n",
    "from matome.engines.cluster import GMMClusterer\n",
    "from matome.engines.embedder import EmbeddingService\n",
    "from matome.engines.interactive_raptor import InteractiveRaptorEngine\n",
    "from matome.engines.raptor import RaptorEngine\n",
    "from matome.engines.token_chunker import JapaneseTokenChunker\n",
    "from matome.utils.store import DiskChunkStore\n",
    "\n",
    "# 1. Configuration\n",
    "config = ProcessingConfig(\n",
    "    max_input_length=100000,\n",
    "    max_tokens=100,  # Small chunks to force tree depth\n",
    "    overlap=10,\n",
    "    max_summary_tokens=50,  # Short summaries for UAT\n",
    "    clustering_algorithm=\"gmm\", # Explicitly set\n",
    "    # If in mock mode, we ensure faster processing but still correct structure\n",
    "    max_retries=1 if mock_mode else 3,\n",
    ")\n",
    "\n",
    "# 2. Dependency Injection\n",
    "# We explicitly initialize all components as per the architecture\n",
    "chunker = JapaneseTokenChunker(config)\n",
    "embedder = EmbeddingService(config)\n",
    "clusterer = GMMClusterer()\n",
    "summarizer = SummarizationAgent(config)\n",
    "\n",
    "# 3. Initialize Batch Engine\n",
    "raptor = RaptorEngine(\n",
    "    chunker=chunker,\n",
    "    embedder=embedder,\n",
    "    clusterer=clusterer,\n",
    "    summarizer=summarizer,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(\"âœ… Engines Initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {},
   "source": [
    "## Part 1: The 'Grok' Moment (Cycle 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Text (Investment Philosophy)\n",
    "# We need enough text to generate at least 2 levels (Chunks -> Summaries -> Root)\n",
    "# Each chunk is roughly 100-200 tokens. We want > 5-10 chunks.\n",
    "\n",
    "base_text = \"\"\"\n",
    "Value investing is an investment paradigm that involves buying securities that appear underpriced by some form of fundamental analysis.\n",
    "All forms of value investing derive from the philosophy of investment taught by Benjamin Graham and David Dodd at Columbia Business School in 1928.\n",
    "The concept of \"margin of safety\" is the principle of buying a security at a significant discount to its intrinsic value, which is thought to provide not only high-return opportunities but also to minimize the downside risk of an investment.\n",
    "Warren Buffett, a student of Graham, is a notable proponent of this strategy.\n",
    "\n",
    "Contrarian investing is an investment style in which investors purposefully go against prevailing market trends by selling when others are buying, and buying when others are selling.\n",
    "A contrarian investor believes that the people who say the market is going up do so only when they are fully invested and have no further purchasing power.\n",
    "At this point, the market is at a peak. When people predict a downturn, they have already sold out, at which point the market can only go up.\n",
    "\"\"\"\n",
    "\n",
    "# Ensure enough length for clustering\n",
    "if mock_mode:\n",
    "    # Repeat more times in mock mode to ensure depth without cost\n",
    "    full_text = (base_text + \"\\n\\n\") * 20\n",
    "else:\n",
    "    full_text = (base_text + \"\\n\\n\") * 10\n",
    "\n",
    "print(f\"Input Text Length: {len(full_text)} chars\")\n",
    "\n",
    "# Run RAPTOR\n",
    "# Use a persistent file for UAT to inspect later\n",
    "db_path = Path(\"tutorials/chunks.db\")\n",
    "if db_path.exists():\n",
    "    db_path.unlink() # Start fresh\n",
    "\n",
    "store = DiskChunkStore(db_path)\n",
    "\n",
    "print(\"ðŸš€ Running RAPTOR Engine... (This may take a moment)\")\n",
    "tree = raptor.run(full_text, store=store)\n",
    "\n",
    "print(\"âœ… Tree Generation Complete.\")\n",
    "print(f\"Root Node ID: {tree.root_node.id}\")\n",
    "print(f\"Tree Levels: {tree.metadata.get('levels')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: UAT-01 (Wisdom Generation)\n",
    "root = tree.root_node\n",
    "\n",
    "print(f\"Root Text: {root.text[:100]}...\")\n",
    "print(f\"Root Level: {root.metadata.dikw_level}\")\n",
    "\n",
    "# Allow weak check for Mock Mode if strategy returns default or something else,\n",
    "# but normally Raptor should set Wisdom for top level.\n",
    "# We check if it is either the Enum value or the string value \"wisdom\"\n",
    "assert root.metadata.dikw_level == DIKWLevel.WISDOM or root.metadata.dikw_level == \"wisdom\", \\\n",
    "    f\"Expected Wisdom, got {root.metadata.dikw_level}\"\n",
    "\n",
    "mo.md(f\"### ðŸŽ¯ **UAT-01 Passed**: Root node is verified as **{root.metadata.dikw_level}**.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {},
   "source": [
    "## Part 2: Semantic Zooming (Cycle 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Interactive Engine for traversal\n",
    "interactive_engine = InteractiveRaptorEngine(\n",
    "    store=store,\n",
    "    summarizer=summarizer,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Verification: UAT-02 (Information Gen) & Semantic Zooming\n",
    "# We want to check Level 1 nodes (summaries of chunks).\n",
    "# These should be 'information' or 'knowledge' depending on depth, but definitely Summaries.\n",
    "\n",
    "level_1_ids = list(store.get_node_ids_by_level(1))\n",
    "print(f\"Found {len(level_1_ids)} Level 1 nodes.\")\n",
    "\n",
    "assert len(level_1_ids) > 0, \"Tree must have at least one level of summaries above chunks.\"\n",
    "\n",
    "# Check a sample L1 node\n",
    "sample_l1_id = level_1_ids[0]\n",
    "sample_l1_node = store.get_node(sample_l1_id)\n",
    "\n",
    "print(f\"Sample L1 Node Level: {sample_l1_node.metadata.dikw_level}\")\n",
    "\n",
    "# Check children are chunks\n",
    "child_ids = sample_l1_node.children_indices\n",
    "first_child = store.get_node(child_ids[0])\n",
    "\n",
    "assert isinstance(first_child, Chunk), \"Children of Level 1 nodes must be Chunks.\"\n",
    "\n",
    "# The DIKW level of L1 should ideally be Information (actionable) or Knowledge (structural).\n",
    "# Default config maps leaf strategy to 'information'.\n",
    "assert sample_l1_node.metadata.dikw_level in [DIKWLevel.INFORMATION, DIKWLevel.KNOWLEDGE, \"information\", \"knowledge\"], \\\n",
    "    f\"Unexpected L1 level: {sample_l1_node.metadata.dikw_level}\"\n",
    "\n",
    "mo.md(\"### ðŸŽ¯ **UAT-02 Passed**: Level 1 nodes are valid Summaries of Chunks (Semantic Zoom Verified).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {},
   "source": [
    "## Part 3: Interactive Refinement (Cycle 02 & 04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: UAT-03 (Single Refinement)\n",
    "\n",
    "# We refine the Root for simplicity, as we know it exists.\n",
    "target_node = root\n",
    "\n",
    "print(f\"Refining Node: {target_node.id}\")\n",
    "instruction = \"Explain this like I'm 5 years old.\"\n",
    "\n",
    "refined_node = interactive_engine.refine_node(target_node.id, instruction)\n",
    "\n",
    "print(f\"Refined Text: {refined_node.text[:50]}...\")\n",
    "print(f\"User Edited: {refined_node.metadata.is_user_edited}\")\n",
    "\n",
    "assert refined_node.metadata.is_user_edited is True\n",
    "assert instruction in refined_node.metadata.refinement_history\n",
    "# Text should change (even in mock mode, it returns \"Summary of ...\")\n",
    "assert refined_node.text != \"\", \"Refined text shouldn't be empty\"\n",
    "\n",
    "mo.md(\"### ðŸŽ¯ **UAT-03 Passed**: Node successfully refined and persisted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: UAT-04 (Concurrency)\n",
    "# Strategy: Spawn a thread that reads the node continuously while the main thread writes to it.\n",
    "\n",
    "stop_event = threading.Event()\n",
    "errors = []\n",
    "\n",
    "def reader_thread():\n",
    "    try:\n",
    "        while not stop_event.is_set():\n",
    "            # Read node\n",
    "            _ = interactive_engine.get_node(target_node.id)\n",
    "            time.sleep(0.05)\n",
    "    except Exception as e:\n",
    "        errors.append(e)\n",
    "\n",
    "t = threading.Thread(target=reader_thread)\n",
    "t.start()\n",
    "\n",
    "try:\n",
    "    # Perform another refinement (Write)\n",
    "    print(\"Running concurrent refinement...\")\n",
    "    interactive_engine.refine_node(target_node.id, \"Make it even simpler.\")\n",
    "    time.sleep(0.5) # Allow some reads to happen\n",
    "finally:\n",
    "    stop_event.set()\n",
    "    t.join()\n",
    "\n",
    "if errors:\n",
    "    print(f\"Concurrency errors encountered: {errors}\")\n",
    "    raise errors[0]\n",
    "\n",
    "mo.md(\"### ðŸŽ¯ **UAT-04 Passed**: Concurrent Read/Write verified without crashing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {},
   "source": [
    "## Part 4: Traceability (Cycle 05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: UAT-07 (Source Verification)\n",
    "\n",
    "# Get source chunks for the refined node\n",
    "source_chunks = list(interactive_engine.get_source_chunks(refined_node.id, limit=5))\n",
    "\n",
    "print(f\"Found {len(source_chunks)} source chunks.\")\n",
    "if len(source_chunks) > 0:\n",
    "    print(f\"Sample Chunk: {source_chunks[0].text[:50]}...\")\n",
    "\n",
    "assert len(source_chunks) > 0\n",
    "assert isinstance(source_chunks[0], Chunk)\n",
    "\n",
    "mo.md(\"### ðŸŽ¯ **UAT-07 Passed**: Traceability to source chunks confirmed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.md(\n",
    "    f\"\"\"\n",
    "    ## Part 5: Launching the GUI (Cycle 05)\n",
    "\n",
    "    The automated verification is complete!\n",
    "\n",
    "    To explore the tree visually:\n",
    "    1. Open a terminal.\n",
    "    2. Run: `uv run matome serve {db_path}`\n",
    "    3. Open your browser to `http://localhost:5006`\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {},
   "source": [
    "# ðŸŽ‰ All Systems Go: Matome 2.0 is ready for Knowledge Installation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "width": "medium"
   },
   "marimo_version": "0.19.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
