{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import uuid\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Any, Iterator, cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from domain_models.config import ProcessingConfig\n",
    "from domain_models.types import DIKWLevel, NodeID\n",
    "from domain_models.manifest import Chunk, SummaryNode\n",
    "from matome.agents.summarizer import SummarizationAgent\n",
    "from matome.engines.cluster import GMMClusterer\n",
    "from matome.engines.embedder import EmbeddingService\n",
    "from matome.engines.interactive_raptor import InteractiveRaptorEngine\n",
    "from matome.engines.raptor import RaptorEngine\n",
    "from matome.engines.token_chunker import JapaneseTokenChunker\n",
    "from matome.interfaces import PromptStrategy\n",
    "from matome.utils.store import DiskChunkStore\n",
    "from matome.exporters.markdown import export_to_markdown\n",
    "from matome.exporters.obsidian import ObsidianCanvasExporter\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, force=True)\n",
    "logger = logging.getLogger(\"matome.tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MOCK CLASSES ---\n",
    "\n",
    "class MockEmbeddingService(EmbeddingService):\n",
    "    \"\"\"Mock Embedder to avoid downloading heavy models.\"\"\"\n",
    "\n",
    "    def __init__(self, config: ProcessingConfig):\n",
    "        super().__init__(config)\n",
    "        self.dim = 384  # Default for all-MiniLM-L6-v2\n",
    "\n",
    "    def embed_strings(self, texts: Any) -> Iterator[list[float]]:\n",
    "        # Return random vectors\n",
    "        for _ in texts:\n",
    "            # Use seed for deterministic results\n",
    "            yield np.random.rand(self.dim).tolist()\n",
    "\n",
    "    def embed_chunks(self, chunks: Iterator[Chunk]) -> Iterator[Chunk]:\n",
    "        for chunk in chunks:\n",
    "            chunk.embedding = np.random.rand(self.dim).tolist()\n",
    "            yield chunk\n",
    "\n",
    "class MockSummarizationAgent(SummarizationAgent):\n",
    "    \"\"\"Mock Agent to return deterministic summaries based on strategy.\"\"\"\n",
    "\n",
    "    def summarize(\n",
    "        self,\n",
    "        text: str,\n",
    "        config: ProcessingConfig | None = None,\n",
    "        strategy: PromptStrategy | None = None,\n",
    "        context: dict[str, Any] | None = None,\n",
    "    ) -> str:\n",
    "        # Check context for refinement instruction\n",
    "        if context and \"instruction\" in context:\n",
    "            return f\"Refined: {context['instruction']} (Original len: {len(text)})\"\n",
    "\n",
    "        # Check strategy for DIKW level\n",
    "        level_name = \"Summary\"\n",
    "        if strategy:\n",
    "            try:\n",
    "                level_name = strategy.target_dikw_level.value.capitalize()\n",
    "            except AttributeError:\n",
    "                level_name = type(strategy).__name__\n",
    "\n",
    "        return f\"{level_name}: {text[:50]}... (Mock Generated)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SETUP & INITIALIZATION ---\n",
    "\n",
    "# Determine mode\n",
    "api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "mock_mode = not api_key or api_key == \"mock\"\n",
    "\n",
    "logger.info(f\"Running in {'MOCK' if mock_mode else 'REAL'} mode.\")\n",
    "\n",
    "# Initialize Config\n",
    "config = ProcessingConfig()\n",
    "\n",
    "# Ensure tutorials directory exists\n",
    "os.makedirs(\"tutorials\", exist_ok=True)\n",
    "\n",
    "# Initialize Components\n",
    "chunker = JapaneseTokenChunker(config)\n",
    "clusterer = GMMClusterer()\n",
    "\n",
    "if mock_mode:\n",
    "    embedder = MockEmbeddingService(config)\n",
    "    summarizer = MockSummarizationAgent(config)\n",
    "else:\n",
    "    embedder = EmbeddingService(config)\n",
    "    summarizer = SummarizationAgent(config)\n",
    "\n",
    "# Initialize Engine\n",
    "engine = RaptorEngine(chunker, embedder, clusterer, summarizer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 1: The \"Grok\" Moment (Cycle 01) - Wisdom Generation ---\n",
    "# Goal: Load text, run Raptor, and verify the Root Node is \"Wisdom\".\n",
    "logger.info(\"Starting Part 1: Wisdom Generation\")\n",
    "\n",
    "# Sample text (simulating a financial document)\n",
    "SAMPLE_TEXT = \"\"\"\n",
    "ã€æŠ•è³‡å“²å­¦ã€‘\n",
    "ãƒãƒªãƒ¥ãƒ¼æŠ•è³‡ã¯ã€ä½•ã‚‰ã‹ã®ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«åˆ†æžã«ã‚ˆã‚ŠéŽå°è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹è¨¼åˆ¸ã‚’è³¼å…¥ã™ã‚‹æŠ•è³‡æ‰‹æ³•ã§ã‚ã‚‹ã€‚\n",
    "ã“ã®æ¦‚å¿µã¯ãƒ™ãƒ³ã‚¸ãƒ£ãƒŸãƒ³ãƒ»ã‚°ãƒ¬ã‚¢ãƒ ã¨ãƒ‡ãƒ“ãƒƒãƒ‰ãƒ»ãƒ‰ãƒƒãƒ‰ã«ã‚ˆã£ã¦æœ€åˆã«åºƒã‚ã‚‰ã‚ŒãŸã€‚\n",
    "ã‚¦ã‚©ãƒ¼ãƒ¬ãƒ³ãƒ»ãƒãƒ•ã‚§ãƒƒãƒˆã¯ã“ã®æˆ¦ç•¥ã®æœ€ã‚‚æœ‰åãªæ”¯æŒè€…ã®ä¸€äººã§ã‚ã‚‹ã€‚\n",
    "\n",
    "ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€‘\n",
    "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€è¡¨ç¾å­¦ç¿’ã‚’ä¼´ã†äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«åŸºã¥ãæ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã®åºƒç¯„ãªãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ä¸€éƒ¨ã§ã‚ã‚‹ã€‚\n",
    "å­¦ç¿’ã¯ã€æ•™å¸«ã‚ã‚Šã€åŠæ•™å¸«ã‚ã‚Šã€ã¾ãŸã¯æ•™å¸«ãªã—ã§è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚\n",
    "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ“ãƒªãƒ¼ãƒ•ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€æ·±å±¤å¼·åŒ–å­¦ç¿’ã€ãƒªã‚«ãƒ¬ãƒ³ãƒˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãªã©ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€éŸ³å£°èªè­˜ã€è‡ªç„¶è¨€èªžå‡¦ç†ã€æ©Ÿæ¢°ç¿»è¨³ã€ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒžãƒ†ã‚£ã‚¯ã‚¹ã€å‰µè–¬ã€åŒ»ç™‚ç”»åƒåˆ†æžã€ææ–™æ¤œæŸ»ã€ãƒœãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãªã©ã®åˆ†é‡Žã«é©ç”¨ã•ã‚Œã€äººé–“ã®å°‚é–€å®¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã«åŒ¹æ•µã—ã€å ´åˆã«ã‚ˆã£ã¦ã¯ãã‚Œã‚’è¶…ãˆã‚‹çµæžœã‚’ç”Ÿã¿å‡ºã—ã¦ã„ã‚‹ã€‚\n",
    "\n",
    "ã€å››å­£å ±ã®èª­ã¿æ–¹ã€‘\n",
    "ä¼šç¤¾å››å­£å ±ã¯ã€æ—¥æœ¬ã®å…¨ä¸Šå ´ä¼æ¥­ã®ãƒ‡ãƒ¼ã‚¿ãƒ–ãƒƒã‚¯ã§ã‚ã‚‹ã€‚\n",
    "æ¥­ç¸¾äºˆæƒ³ã€è²¡å‹™çŠ¶æ³ã€æ ªä¸»æ§‹æˆãªã©ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚\n",
    "ç‰¹ã«é‡è¦ãªã®ã¯ã€Œæ¥­ç¸¾æ¬„ã€ã§ã‚ã‚Šã€å£²ä¸Šé«˜ã‚„å–¶æ¥­åˆ©ç›Šã®æŽ¨ç§»ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ã€ä¼æ¥­ã®æˆé•·æ€§ã‚’åˆ¤æ–­ã§ãã‚‹ã€‚\n",
    "ã¾ãŸã€ã€Œææ–™æ¬„ã€ã«ã¯ã€æ–°è£½å“ã®é–‹ç™ºçŠ¶æ³ã‚„ææºè©±ãªã©ã€å°†æ¥ã®æ ªä¾¡ã«å½±éŸ¿ã‚’ä¸Žãˆã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹æƒ…å ±ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ã€‚\n",
    "PERï¼ˆæ ªä¾¡åŽç›ŠçŽ‡ï¼‰ã‚„PBRï¼ˆæ ªä¾¡ç´”è³‡ç”£å€çŽ‡ï¼‰ãªã©ã®æŒ‡æ¨™ã‚‚é‡è¦ã§ã‚ã‚‹ãŒã€ã“ã‚Œã‚‰ã¯ã‚ãã¾ã§éŽåŽ»ã®å®Ÿç¸¾ã«åŸºã¥ãã‚‚ã®ã§ã‚ã‚Šã€å°†æ¥ã®æˆé•·æ€§ã‚’åŠ å‘³ã—ã¦åˆ¤æ–­ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚\n",
    "\"\"\" * 3  # Duplicate to ensure enough content for chunking\n",
    "\n",
    "# 1. Chunking\n",
    "chunks = list(chunker.split_text(SAMPLE_TEXT, config))\n",
    "logger.info(f\"Generated {len(chunks)} chunks.\")\n",
    "assert len(chunks) > 0, \"Should generate chunks\"\n",
    "\n",
    "# 2. Visualize Chunks (Quick verification)\n",
    "print(\"--- First 3 Chunks ---\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"Chunk {i}: {chunk.text.strip()[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 1 Continued: Running the Engine ---\n",
    "\n",
    "# Setup temporary DB\n",
    "db_path = Path(\"tutorials/chunks.db\")\n",
    "if db_path.exists():\n",
    "    db_path.unlink()\n",
    "\n",
    "store = DiskChunkStore(db_path)\n",
    "\n",
    "# Run Engine\n",
    "try:\n",
    "    root_tree = engine.run(SAMPLE_TEXT, store)\n",
    "    logger.info(\"Raptor Engine finished successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Raptor Engine failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Validation: Verify Root is Wisdom (UAT-01)\n",
    "root_node = root_tree.root_node\n",
    "logger.info(f\"Root Node Level: {root_node.level}, DIKW: {root_node.metadata.dikw_level}\")\n",
    "\n",
    "# Note: In mock mode, Raptor might not strictly assign \"WISDOM\" if using default simple strategies\n",
    "# unless config is set to use WisdomStrategy for root.\n",
    "# We should verify it is SummaryNode and has a DIKW level.\n",
    "# The default Raptor engine assigns DIKW level based on topology key \"root\".\n",
    "\n",
    "# Assert Root is Wisdom (or whatever config says, default is WISDOM)\n",
    "assert root_node.metadata.dikw_level == DIKWLevel.WISDOM, f\"Root should be Wisdom, got {root_node.metadata.dikw_level}\"\n",
    "\n",
    "# Export to Markdown for visual check\n",
    "md_output = export_to_markdown(root_tree, store)\n",
    "with open(\"summary_all.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md_output)\n",
    "\n",
    "print(\"âœ… Part 1 Passed: Wisdom Generation & Markdown Export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 2: Semantic Zooming (Cycle 03) ---\n",
    "# Goal: Traverse the tree and verify hierarchy (UAT-02, UAT-05 Logic)\n",
    "logger.info(\"Starting Part 2: Semantic Zooming\")\n",
    "\n",
    "# The root is Wisdom. Its children should be Knowledge.\n",
    "# Knowledge children should be Information (or Data if tree is shallow).\n",
    "\n",
    "# Check children of Root\n",
    "children_ids = root_node.children_indices\n",
    "assert len(children_ids) > 0, \"Root should have children\"\n",
    "\n",
    "first_child = store.get_node(children_ids[0])\n",
    "\n",
    "if isinstance(first_child, SummaryNode):\n",
    "    logger.info(f\"Level 2 Node DIKW: {first_child.metadata.dikw_level}\")\n",
    "    # Ideally Knowledge, but depends on tree depth.\n",
    "    # If depth is small, might go straight to Data or Information.\n",
    "    # But let's just verify we can traverse.\n",
    "else:\n",
    "    logger.info(\"Level 2 Node is Chunk (Data). Tree is shallow.\")\n",
    "\n",
    "# Validate Hierarchy Depth\n",
    "max_level = store.get_max_level()\n",
    "logger.info(f\"Tree Max Level: {max_level}\")\n",
    "assert max_level >= 1\n",
    "\n",
    "print(\"âœ… Part 2 Passed: Hierarchy Traversal Verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 3: Interactive Refinement (Cycle 02 & 04) ---\n",
    "# Goal: Refine a node and verify persistence (UAT-03, UAT-06 Backend)\n",
    "\n",
    "interactive = InteractiveRaptorEngine(store, summarizer, config)\n",
    "target_node_id = root_node.id\n",
    "instruction = \"Explain like I'm 5\"\n",
    "\n",
    "refined_node = interactive.refine_node(str(target_node_id), instruction)\n",
    "\n",
    "# Validation\n",
    "assert refined_node.metadata.is_user_edited is True\n",
    "assert instruction in refined_node.metadata.refinement_history\n",
    "assert refined_node.id == str(target_node_id) # ID must not change\n",
    "\n",
    "# Verify persistence\n",
    "persisted_node = store.get_node(target_node_id)\n",
    "assert persisted_node.metadata.is_user_edited is True\n",
    "assert persisted_node.text == refined_node.text\n",
    "\n",
    "print(f\"Refined Node: {refined_node.text[:50]}...\")\n",
    "print(\"âœ… Part 3 Passed: Interactive Refinement Verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 4: Concurrency (Cycle 02) ---\n",
    "# Goal: Read/Write simultaneously without locking DB (UAT-04)\n",
    "# We will launch a read operation in a loop while performing a write.\n",
    "\n",
    "logger.info(\"Starting Part 4: Concurrency Test\")\n",
    "\n",
    "def read_loop(node_id, stop_event):\n",
    "    reads = 0\n",
    "    while not stop_event.is_set():\n",
    "        _ = store.get_node(node_id)\n",
    "        reads += 1\n",
    "        # slight sleep to yield gil\n",
    "        import time\n",
    "        time.sleep(0.01)\n",
    "    return reads\n",
    "\n",
    "stop_event = threading.Event()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    # Start reader\n",
    "    reader_future = executor.submit(read_loop, target_node_id, stop_event)\n",
    "\n",
    "    # Perform Write (Refinement)\n",
    "    try:\n",
    "        _ = interactive.refine_node(str(target_node_id), \"Concurrency Test Update\")\n",
    "        logger.info(\"Concurrent Write Completed\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Concurrent Write Failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Stop reader\n",
    "    stop_event.set()\n",
    "    reads = reader_future.result()\n",
    "    logger.info(f\"Concurrent Reads Completed: {reads}\")\n",
    "\n",
    "print(\"âœ… Part 4 Passed: Concurrency Test (Read/Write) Verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 5: Traceability (Cycle 05) ---\n",
    "# Goal: Get source chunks for a node (UAT-07)\n",
    "\n",
    "source_chunks = list(interactive.get_source_chunks(str(target_node_id)))\n",
    "assert len(source_chunks) > 0\n",
    "assert isinstance(source_chunks[0], Chunk)\n",
    "\n",
    "print(f\"Traced {len(source_chunks)} source chunks for node {target_node_id}.\")\n",
    "print(\"âœ… Part 5 Passed: Traceability Verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 6: Launching the GUI & Export (UAT-05) ---\n",
    "\n",
    "# Export Canvas\n",
    "exporter = ObsidianCanvasExporter(config)\n",
    "output_path = Path(\"summary_kj.canvas\")\n",
    "exporter.export(root_tree, output_path, store)\n",
    "assert output_path.exists()\n",
    "\n",
    "print(\"âœ… Part 6 Passed: Canvas Exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ‰ All Systems Go: Matome 2.0 is ready for Knowledge Installation.\")\n",
    "print(f\"To explore the tree visually, run: uv run matome serve {db_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "width": "medium"
   },
   "header": "# Copyright (c) 2024 Matome Project\n# Validated by QA Lead & Developer Advocate\n",
   "marimo_version": "0.19.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
