{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Iterator, Iterable, Any\n",
    "import numpy as np\n",
    "import marimo as mo\n",
    "\n",
    "# Adjust path to include src if running from root or tutorials\n",
    "current_dir = Path.cwd()\n",
    "if (current_dir / \"src\").exists():\n",
    "    sys.path.append(str(current_dir / \"src\"))\n",
    "elif (current_dir.parent / \"src\").exists():\n",
    "    sys.path.append(str(current_dir.parent / \"src\"))\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"matome.uat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.md(\n",
    "    \"\"\"\n",
    "    # Matome 2.0: User Acceptance Test & Tutorial\n",
    "\n",
    "    This notebook demonstrates the core capabilities of the Matome 2.0 \"Knowledge Installation\" system.\n",
    "    It covers the entire pipeline from raw text to a structured, interactive knowledge base.\n",
    "\n",
    "    **Scenarios:**\n",
    "    1.  **Cycle 01: DIKW Generation**: Generate a tree where Root is Wisdom.\n",
    "    2.  **Cycle 03: Semantic Zooming**: Traverse from Wisdom -> Knowledge -> Information -> Data.\n",
    "    3.  **Cycle 02/04: Interactive Refinement**: Refine a node and verify persistence.\n",
    "    4.  **Cycle 05: Traceability**: Verify source chunks for a summary node.\n",
    "    5.  **GUI Launch**: Instructions to explore visually.\n",
    "\n",
    "    **Modes:**\n",
    "    *   **Real Mode**: Uses OpenAI/OpenRouter API for actual summarization (Requires `OPENROUTER_API_KEY`).\n",
    "    *   **Mock Mode**: Uses random embeddings and dummy summaries (Default if no key found).\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Determine Mode\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "mock_mode = not bool(api_key) or api_key == \"mock\"\n",
    "\n",
    "if mock_mode:\n",
    "    mode_msg = \"âš ï¸ **MOCK MODE ACTIVE** (No API Key found or set to 'mock'). Using dummy data.\"\n",
    "else:\n",
    "    mode_msg = \"âœ… **REAL MODE ACTIVE**. Using live API.\"\n",
    "\n",
    "mo.md(mode_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration & Mocks ---\n",
    "from domain_models.config import ProcessingConfig\n",
    "from domain_models.manifest import Chunk, SummaryNode\n",
    "from domain_models.types import DIKWLevel, NodeID\n",
    "from matome.engines.embedder import EmbeddingService\n",
    "from matome.agents.summarizer import SummarizationAgent\n",
    "from matome.interfaces import PromptStrategy\n",
    "\n",
    "# Initialize Config\n",
    "# Ensure strict consistency for testing\n",
    "config = ProcessingConfig(\n",
    "    max_tokens=500, # Reduce for testing to force more chunks\n",
    "    max_summary_tokens=200, \n",
    "    dikw_topology={\n",
    "        \"root\": DIKWLevel.WISDOM,\n",
    "        \"intermediate\": DIKWLevel.KNOWLEDGE,\n",
    "        \"leaf\": DIKWLevel.INFORMATION,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Mock Classes\n",
    "class MockEmbeddingService(EmbeddingService):\n",
    "    \"\"\"Generates random embeddings for testing.\"\"\"\n",
    "    def __init__(self, config: ProcessingConfig):\n",
    "        super().__init__(config)\n",
    "        self.dim = 384  # Simulating all-MiniLM-L6-v2\n",
    "\n",
    "    def embed_strings(self, texts: list[str] | tuple[str, ...]) -> Iterator[list[float]]:\n",
    "        for _ in texts:\n",
    "            # Deterministic random for stability based on length\n",
    "            yield list(np.random.rand(self.dim))\n",
    "\n",
    "    def embed_chunks(self, chunks: list[Chunk]) -> Iterator[Chunk]:\n",
    "        for chunk in chunks:\n",
    "            chunk.embedding = list(np.random.rand(self.dim))\n",
    "            yield chunk\n",
    "\n",
    "class MockSummarizationAgent(SummarizationAgent):\n",
    "    \"\"\"Generates dummy summaries respecting DIKW levels.\"\"\"\n",
    "    def __init__(self, config: ProcessingConfig):\n",
    "        self.config = config\n",
    "        self.mock_mode = True\n",
    "        self.model_name = \"mock-model\"\n",
    "        self.llm = None\n",
    "\n",
    "    def summarize(\n",
    "        self,\n",
    "        text: str,\n",
    "        config: ProcessingConfig | None = None,\n",
    "        strategy: PromptStrategy | None = None,\n",
    "        context: dict[str, Any] | None = None,\n",
    "    ) -> str:\n",
    "        prefix = \"Summary\"\n",
    "        if strategy:\n",
    "            # strategy.dikw_level is likely a DIKWLevel Enum member\n",
    "            try:\n",
    "                # Access the .value if it's an enum, or just str()\n",
    "                level = getattr(strategy, \"target_dikw_level\", \"UNKNOWN\")\n",
    "                # If it's an Enum, get value\n",
    "                if hasattr(level, \"value\"):\n",
    "                    level = level.value\n",
    "            except AttributeError:\n",
    "                level = \"UNKNOWN\"\n",
    "\n",
    "            # Check context for instruction (Refinement)\n",
    "            instruction = context.get(\"instruction\") if context else None\n",
    "            if instruction:\n",
    "                return f\"[REFINED] {instruction} -> {text[:30]}...\"\n",
    "\n",
    "            prefix = f\"[{str(level).upper()}] Summary\"\n",
    "\n",
    "        return f\"{prefix} of: {text[:30]}... (Mocked Content)\"\n",
    "\n",
    "# Factory\n",
    "def get_services(cfg, is_mock):\n",
    "    if is_mock:\n",
    "        return MockEmbeddingService(cfg), MockSummarizationAgent(cfg)\n",
    "    else:\n",
    "        return EmbeddingService(cfg), SummarizationAgent(cfg)\n",
    "\n",
    "mo.md(\"### System Configuration Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 0: Setup Test Data ---\n",
    "test_data_dir = Path(\"test_data\")\n",
    "test_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "sample_file = test_data_dir / \"investment_philosophy.txt\"\n",
    "\n",
    "# Generate content if missing\n",
    "content = \"\"\n",
    "# Part 1: Wisdom\n",
    "content += \"Chapter 1: The Mindset of a Sage Investor.\\n\"\n",
    "content += \"True investment wisdom lies not in chasing trends but in understanding the immutable laws of value. \" * 5 + \"\\n\"\n",
    "content += \"Patience is the investor's greatest asset. Emotional discipline separates the master from the novice. \" * 5 + \"\\n\"\n",
    "\n",
    "# Part 2: Knowledge\n",
    "content += \"Chapter 2: The Mechanics of Wealth.\\n\"\n",
    "content += \"Compounding is the eighth wonder of the world. Understanding exponential growth is key. \" * 5 + \"\\n\"\n",
    "content += \"Asset allocation determines 90% of returns. Diversification is the only free lunch in finance. \" * 5 + \"\\n\"\n",
    "\n",
    "# Part 3: Information\n",
    "content += \"Chapter 3: Actionable Steps.\\n\"\n",
    "content += \"1. Review your portfolio quarterly. 2. Rebalance if drift exceeds 5%. 3. Tax loss harvest in December. \" * 5 + \"\\n\"\n",
    "content += \"Check the expense ratios of your ETFs. Ensure they are below 0.10%. Automate your savings. \" * 5 + \"\\n\"\n",
    "\n",
    "# Repeat to ensure length\n",
    "content = content * 20\n",
    "\n",
    "sample_file.write_text(content, encoding=\"utf-8\")\n",
    "\n",
    "mo.md(f\"### Test Data Ready\\n- `{sample_file}`\\n- Size: {len(content)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Cycle 01 - DIKW Generation ---\n",
    "from matome.engines.raptor import RaptorEngine\n",
    "from matome.engines.token_chunker import JapaneseTokenChunker\n",
    "from matome.engines.cluster import GMMClusterer\n",
    "from matome.utils.store import DiskChunkStore\n",
    "\n",
    "mo.md(\"## 1. Cycle 01: DIKW Generation\")\n",
    "\n",
    "# Clean DB\n",
    "store_path = Path(\"tutorials/chunks.db\")\n",
    "if store_path.exists():\n",
    "    store_path.unlink()\n",
    "\n",
    "store = DiskChunkStore(db_path=store_path)\n",
    "\n",
    "# Setup Components\n",
    "chunker = JapaneseTokenChunker(config)\n",
    "clusterer = GMMClusterer()\n",
    "embedder, summarizer = get_services(config, mock_mode)\n",
    "\n",
    "engine = RaptorEngine(\n",
    "    chunker=chunker,\n",
    "    embedder=embedder,\n",
    "    clusterer=clusterer,\n",
    "    summarizer=summarizer,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Run Pipeline\n",
    "text = sample_file.read_text(encoding=\"utf-8\")\n",
    "tree = engine.run(text, store=store)\n",
    "\n",
    "# Verify Root is Wisdom (UAT-01)\n",
    "root_node = tree.root_node\n",
    "dikw_level = root_node.metadata.dikw_level\n",
    "\n",
    "# Assertion\n",
    "assert dikw_level == DIKWLevel.WISDOM, f\"Root node should be WISDOM, got {dikw_level}\"\n",
    "\n",
    "mo.md(\n",
    "    f\"### DIKW Generation Successful (UAT-01)\\n\"\n",
    "    f\"Root Node ID: `{root_node.id}`\\n\"\n",
    "    f\"DIKW Level: **{dikw_level}**\\n\"\n",
    "    f\"Text Preview: {root_node.text[:100]}...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Cycle 03 - Semantic Zooming ---\n",
    "mo.md(\"## 2. Cycle 03: Semantic Zooming\")\n",
    "\n",
    "# Traverse hierarchy\n",
    "layers = {}\n",
    "layers[1] = [tree.root_node]\n",
    "\n",
    "def get_children_nodes(parent_nodes):\n",
    "    children = []\n",
    "    for p in parent_nodes:\n",
    "        # child indices can be str (SummaryNode) or int (Chunk)\n",
    "        # In RaptorEngine, children_indices are stored in metadata or distinct field depending on implementation\n",
    "        # Checking SummaryNode schema\n",
    "        child_ids = [str(c) for c in p.children_indices]\n",
    "        nodes = list(store.get_nodes(child_ids))\n",
    "        children.extend([n for n in nodes if n is not None])\n",
    "    return children\n",
    "\n",
    "current_layer_nodes = layers[1]\n",
    "depth = 1\n",
    "hierarchy_desc = []\n",
    "\n",
    "leaf_summaries = []\n",
    "\n",
    "hierarchy_desc.append(f\"**Level {depth} ({current_layer_nodes[0].metadata.dikw_level})**: {len(current_layer_nodes)} node(s)\")\n",
    "\n",
    "while True:\n",
    "    next_nodes = get_children_nodes(current_layer_nodes)\n",
    "    if not next_nodes:\n",
    "        break\n",
    "\n",
    "    first_child = next_nodes[0]\n",
    "    depth += 1\n",
    "\n",
    "    if hasattr(first_child, \"children_indices\"): # SummaryNode\n",
    "         level_name = first_child.metadata.dikw_level\n",
    "         hierarchy_desc.append(f\"**Level {depth} ({level_name})**: {len(next_nodes)} node(s)\")\n",
    "         current_layer_nodes = next_nodes\n",
    "\n",
    "         # Check if these are leaf summaries (children are chunks)\n",
    "         # To do this robustly, check the first child's children\n",
    "         if next_nodes:\n",
    "             grand_children = get_children_nodes([next_nodes[0]])\n",
    "             if grand_children and not hasattr(grand_children[0], \"children_indices\"):\n",
    "                 leaf_summaries.extend(next_nodes)\n",
    "    else: # Chunk\n",
    "         hierarchy_desc.append(f\"**Level {depth} (DATA)**: {len(next_nodes)} chunk(s)\")\n",
    "         break\n",
    "\n",
    "# UAT-02: Verify Leaf Summaries are INFORMATION (if hierarchy exists)\n",
    "if leaf_summaries:\n",
    "    for node in leaf_summaries:\n",
    "        assert node.metadata.dikw_level == DIKWLevel.INFORMATION, \\\n",
    "            f\"Leaf summary {node.id} should be INFORMATION, got {node.metadata.dikw_level}\"\n",
    "    mo.md(f\"âœ… **UAT-02 Verified**: {len(leaf_summaries)} leaf summaries are correctly labeled as INFORMATION.\")\n",
    "else:\n",
    "     mo.md(\"âš ï¸ **UAT-02 Skipped**: Hierarchy too shallow for Information level.\")\n",
    "\n",
    "mo.md(f\"### Hierarchy Verified\\n\" + \"\\n\".join([f\"- {h}\" for h in hierarchy_desc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Cycle 02/04 - Interactive Refinement ---\n",
    "from matome.engines.interactive_raptor import InteractiveRaptorEngine\n",
    "\n",
    "mo.md(\"## 3. Cycle 02/04: Interactive Refinement\")\n",
    "\n",
    "interactive_engine = InteractiveRaptorEngine(store, summarizer, config)\n",
    "\n",
    "# UAT-03: Pick a node to refine. Ideally a Knowledge node (Level 2).\n",
    "target_node = root_node\n",
    "\n",
    "# Try to find a child node\n",
    "children = get_children_nodes([root_node])\n",
    "if children and hasattr(children[0], \"children_indices\"):\n",
    "    target_node = children[0]\n",
    "\n",
    "instruction = \"Explain like I'm 5\"\n",
    "\n",
    "# Refine\n",
    "refined_node = interactive_engine.refine_node(target_node.id, instruction)\n",
    "\n",
    "# Verify\n",
    "assert refined_node.metadata.is_user_edited == True\n",
    "assert instruction in refined_node.metadata.refinement_history\n",
    "\n",
    "# Verify persistence\n",
    "persisted_node = store.get_node(target_node.id)\n",
    "assert persisted_node.text == refined_node.text\n",
    "assert persisted_node.metadata.is_user_edited == True\n",
    "\n",
    "mo.md(\n",
    "    f\"### Refinement Successful (UAT-03)\\n\"\n",
    "    f\"Node `{target_node.id}` ({target_node.metadata.dikw_level}) updated.\\n\"\n",
    "    f\"Instruction: *'{instruction}'*\\n\"\n",
    "    f\"New Text: {refined_node.text[:100]}...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Cycle 05 - Traceability ---\n",
    "mo.md(\"## 4. Cycle 05: Traceability\")\n",
    "\n",
    "# Get source chunks for the refined node\n",
    "source_chunks = list(interactive_engine.get_source_chunks(target_node.id))\n",
    "\n",
    "assert len(source_chunks) > 0\n",
    "first_chunk = source_chunks[0]\n",
    "\n",
    "mo.md(\n",
    "    f\"### Traceability Verified (UAT-07)\\n\"\n",
    "    f\"Node `{target_node.id}` traces back to **{len(source_chunks)}** original chunks.\\n\"\n",
    "    f\"First Chunk Preview: *{first_chunk.text[:50]}...*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: GUI Launch ---\n",
    "mo.md(\n",
    "    f\"\"\"\n",
    "    ## ðŸŽ‰ All Systems Go!\n",
    "\n",
    "    The Matome 2.0 pipeline has been verified.\n",
    "    You can now launch the interactive GUI to explore the generated knowledge base.\n",
    "\n",
    "    Run this command in your terminal:\n",
    "    ```bash\n",
    "    uv run matome serve {store_path}\n",
    "    ```\n",
    "    \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "width": "medium"
   },
   "marimo_version": "0.19.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
