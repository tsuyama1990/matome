{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import uuid\n",
    "from collections.abc import Iterable, Iterator\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path if running from root\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from domain_models.config import ProcessingConfig\n",
    "from domain_models.manifest import Chunk, SummaryNode\n",
    "from domain_models.types import DIKWLevel\n",
    "from matome.agents.summarizer import SummarizationAgent\n",
    "from matome.engines.cluster import GMMClusterer\n",
    "from matome.engines.embedder import EmbeddingService\n",
    "from matome.engines.interactive_raptor import InteractiveRaptorEngine\n",
    "from matome.engines.raptor import RaptorEngine\n",
    "from matome.engines.token_chunker import JapaneseTokenChunker\n",
    "from matome.utils.store import DiskChunkStore\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"matome.tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockEmbeddingService:\n",
    "    \"\"\"Mock embedding service that returns random vectors.\"\"\"\n",
    "\n",
    "    def __init__(self, config: ProcessingConfig) -> None:\n",
    "        self.config = config\n",
    "        # Use fixed seed for reproducibility in tests\n",
    "        np.random.seed(42)\n",
    "\n",
    "    def embed_strings(self, texts: Iterable[str]) -> Iterator[list[float]]:\n",
    "        \"\"\"Generate random embeddings for strings.\"\"\"\n",
    "        for _ in texts:\n",
    "            # Generate random vector of size 384 (standard for small models)\n",
    "            yield np.random.rand(384).tolist()\n",
    "\n",
    "    def embed_chunks(self, chunks: Iterable[Any]) -> Iterator[Any]:\n",
    "        \"\"\"Generate random embeddings for chunks.\"\"\"\n",
    "        for chunk in chunks:\n",
    "            chunk.embedding = np.random.rand(384).tolist()\n",
    "            yield chunk\n",
    "\n",
    "logger.info(\"MockEmbeddingService defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Configuration and Environment\n",
    "\n",
    "# 1. Setup DB Path\n",
    "db_path = \"tutorials/chunks.db\"\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "if os.path.exists(f\"{db_path}-shm\"):\n",
    "    os.remove(f\"{db_path}-shm\")\n",
    "if os.path.exists(f\"{db_path}-wal\"):\n",
    "    os.remove(f\"{db_path}-wal\")\n",
    "\n",
    "# 2. Setup Config\n",
    "# Use 'mock' API key if not present to trigger mock mode in agents\n",
    "if not os.getenv(\"OPENAI_API_KEY\") and not os.getenv(\"OPENROUTER_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"mock\"\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = \"mock\"\n",
    "    logger.info(\"Running in MOCK MODE (No API Key found)\")\n",
    "else:\n",
    "    logger.info(\"Running in REAL MODE (API Key found)\")\n",
    "\n",
    "config = ProcessingConfig(\n",
    "    max_tokens=100,  # Small chunk size to force multiple chunks for small text\n",
    "    max_summary_tokens=50,\n",
    "    clustering_probability_threshold=0.1, # Low threshold to ensure clustering\n",
    "    umap_n_neighbors=2, # Small number for small dataset\n",
    "    umap_n_components=2,\n",
    "    umap_min_dist=0.0,\n",
    ")\n",
    "\n",
    "# 3. Initialize Components\n",
    "store = DiskChunkStore(db_path=Path(db_path))\n",
    "chunker = JapaneseTokenChunker(config)\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\") == \"mock\":\n",
    "    embedder = MockEmbeddingService(config)\n",
    "else:\n",
    "    # Reuse imported EmbeddingService\n",
    "    embedder = EmbeddingService(config)\n",
    "\n",
    "# Summarization Agent (Mock mode handled internally by checking API key)\n",
    "summarizer = SummarizationAgent(config)\n",
    "\n",
    "logger.info(\"Components initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle 01: Wisdom Generation (Build the Tree)\n",
    "\n",
    "# Sample Text (Investment Philosophy style)\n",
    "sample_text = \"\"\"\n",
    "é•·æœŸæŠ•è³‡ã®åŸºæœ¬ã¯ã€ä¼æ¥­ã®æˆé•·ã¨å…±ã«è³‡ç”£ã‚’å¢—ã‚„ã™ã“ã¨ã§ã™ã€‚\n",
    "çŸ­æœŸçš„ãªå¸‚å ´ã®å¤‰å‹•ã«æƒ‘ã‚ã•ã‚Œãšã€æœ¬è³ªçš„ãªä¾¡å€¤ã‚’è¦‹æ¥µã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "è¤‡åˆ©ã®åŠ¹æžœã¯æ™‚é–“ã‚’å‘³æ–¹ã«ã¤ã‘ã‚‹ã“ã¨ã§æœ€å¤§åŒ–ã•ã‚Œã¾ã™ã€‚\n",
    "é›ªã ã‚‹ã¾å¼ã«è³‡ç”£ãŒå¢—ãˆã‚‹ã“ã®ä»•çµ„ã¿ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚\n",
    "\n",
    "ãƒªã‚¹ã‚¯ç®¡ç†ã¯åˆ†æ•£æŠ•è³‡ã«ã‚ˆã£ã¦è¡Œã„ã¾ã™ã€‚\n",
    "ä¸€ã¤ã®ã‚«ã‚´ã«ã™ã¹ã¦ã®åµã‚’ç››ã‚‹ãªã€ã¨ã„ã†æ ¼è¨€ã®é€šã‚Šã§ã™ã€‚\n",
    "\n",
    "æœ€å¾Œã«ã€è‡ªå·±ã¸ã®æŠ•è³‡ã‚‚å¿˜ã‚Œã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚\n",
    "çŸ¥è­˜ã“ããŒæœ€å¤§ã®é˜²å¾¡ã§ã‚ã‚Šã€æœ€å¤§ã®æ­¦å™¨ã¨ãªã‚‹ã®ã§ã™ã€‚\n",
    "\"\"\"\n",
    "\n",
    "logger.info(\"Starting Cycle 01: Wisdom Generation...\")\n",
    "\n",
    "clusterer = GMMClusterer()\n",
    "\n",
    "# Initialize Raptor Engine\n",
    "engine = RaptorEngine(\n",
    "    chunker=chunker,\n",
    "    embedder=embedder,\n",
    "    clusterer=clusterer,\n",
    "    summarizer=summarizer,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Run Engine\n",
    "tree = engine.run(sample_text, store=store)\n",
    "\n",
    "logger.info(f\"Tree generation complete. Root ID: {tree.root_node.id}\")\n",
    "\n",
    "# Validation\n",
    "root_node = tree.root_node\n",
    "logger.info(f\"Root Node DIKW Level: {root_node.metadata.dikw_level}\")\n",
    "\n",
    "assert root_node is not None\n",
    "assert root_node.metadata.dikw_level.value in [\"wisdom\", \"knowledge\", \"information\"]\n",
    "\n",
    "logger.info(\"âœ… Cycle 01 Passed: Tree built and Root Node verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle 03: Semantic Zooming (Traverse Tree)\n",
    "\n",
    "logger.info(\"Starting Cycle 03: Semantic Zooming...\")\n",
    "\n",
    "# 1. Get Root (Wisdom)\n",
    "root = tree.root_node\n",
    "print(f\"L1 (Root): {root.text[:50]}...\")\n",
    "\n",
    "# 2. Get Children (Knowledge/Information)\n",
    "# Using store to fetch children\n",
    "child_ids = root.children_indices\n",
    "children = list(store.get_nodes(child_ids))\n",
    "\n",
    "logger.info(f\"Found {len(children)} children for Root.\")\n",
    "\n",
    "for child in children:\n",
    "    if child:\n",
    "        is_summary = hasattr(child, \"metadata\") and hasattr(child.metadata, \"dikw_level\")\n",
    "        type_str = child.metadata.dikw_level.value if is_summary else \"DATA (Chunk)\"\n",
    "        print(f\"  - L2 ({type_str}): {child.text[:30]}...\")\n",
    "\n",
    "# Validation\n",
    "assert len(children) > 0\n",
    "\n",
    "logger.info(\"âœ… Cycle 03 Passed: Tree traversal verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle 02/04: Interactive Refinement\n",
    "\n",
    "logger.info(\"Starting Cycle 02/04: Interactive Refinement...\")\n",
    "\n",
    "interactive_engine = InteractiveRaptorEngine(\n",
    "    store=store,\n",
    "    summarizer=summarizer,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# 1. Select a node to refine (Root node for simplicity)\n",
    "node_id = root_node.id\n",
    "instruction = \"Make it more concise and focused on risk.\"\n",
    "\n",
    "logger.info(f\"Refining node {node_id} with instruction: '{instruction}'\")\n",
    "\n",
    "# 2. Call Refine\n",
    "updated_node = interactive_engine.refine_node(node_id, instruction)\n",
    "\n",
    "# 3. Validation\n",
    "assert updated_node.id == node_id\n",
    "assert updated_node.metadata.is_user_edited is True\n",
    "assert instruction in updated_node.metadata.refinement_history\n",
    "\n",
    "print(f\"Original Text: {root_node.text[:50]}...\")\n",
    "print(f\"Refined Text:  {updated_node.text[:50]}...\")\n",
    "\n",
    "# Check if text changed\n",
    "assert updated_node.text != root_node.text or \"Summary of\" in updated_node.text\n",
    "\n",
    "logger.info(\"âœ… Cycle 02/04 Passed: Node refinement verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle 05: Traceability (Source Verification)\n",
    "\n",
    "logger.info(\"Starting Cycle 05: Traceability...\")\n",
    "\n",
    "# 1. Get Source Chunks for the node\n",
    "source_chunks = list(interactive_engine.get_source_chunks(node_id))\n",
    "\n",
    "logger.info(f\"Found {len(source_chunks)} source chunks.\")\n",
    "\n",
    "# 2. Validation\n",
    "assert len(source_chunks) > 0\n",
    "\n",
    "first_chunk_text = source_chunks[0].text\n",
    "assert len(first_chunk_text) > 0\n",
    "\n",
    "print(f\"Source Chunk 1: {first_chunk_text[:50]}...\")\n",
    "\n",
    "logger.info(\"âœ… Cycle 05 Passed: Source chunks retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "logger.info(\"ðŸŽ‰ All Systems Go: Matome 2.0 is ready for Knowledge Installation.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "width": "medium"
   },
   "marimo_version": "0.19.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
