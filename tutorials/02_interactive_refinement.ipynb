{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 02: Interactive Refinement (Deep Dive)\n",
    "\n",
    "Goal: Demonstrate the ability to \"talk to your knowledge base\" by refining specific nodes.\n",
    "\n",
    "We will:\n",
    "1.  Load the knowledge graph created in Tutorial 01.\n",
    "2.  Select a specific \"Knowledge\" node.\n",
    "3.  Refine it with an instruction (e.g., \"Explain this to a 5-year-old\").\n",
    "4.  Verify the update and trace back to source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from collections.abc import Iterable, Iterator\n",
    "import numpy as np\n",
    "\n",
    "from domain_models.config import ProcessingConfig\n",
    "from domain_models.manifest import SummaryNode, Chunk\n",
    "from matome.engines.embedder import EmbeddingService\n",
    "from matome.engines.interactive_raptor import InteractiveRaptorEngine\n",
    "from matome.agents.summarizer import SummarizationAgent\n",
    "from matome.agents.strategies import BaseSummaryStrategy\n",
    "from matome.utils.store import DiskChunkStore\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "logger = logging.getLogger(\"matome\")\n",
    "\n",
    "# Force Mock Mode\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = \"mock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Embedding Service (Same as Tutorial 01)\n",
    "class MockEmbeddingService(EmbeddingService):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.dim = 384\n",
    "\n",
    "    def embed_strings(self, texts: Iterable[str]) -> Iterator[list[float]]:\n",
    "        for _ in texts:\n",
    "            vec = np.random.rand(self.dim)\n",
    "            yield (vec / np.linalg.norm(vec)).tolist()\n",
    "\n",
    "# Mock Agent with specific response for refinement\n",
    "class RefinementMockAgent(SummarizationAgent):\n",
    "    def _handle_mock_mode(\n",
    "        self,\n",
    "        safe_text_str: str,\n",
    "        context: dict[str, Any] | None,\n",
    "        request_id: str,\n",
    "        strategy: Any = None,\n",
    "    ) -> SummaryNode:\n",
    "        # Check if we are refining\n",
    "        instruction = context.get(\"instruction\", \"\") if context else \"\"\n",
    "        \n",
    "        if instruction:\n",
    "            summary = f\"REFINED: {instruction} -> content updated.\"\n",
    "        else:\n",
    "            summary = f\"Summary of {safe_text_str[:20]}...\"\n",
    "            \n",
    "        return SummaryNode(\n",
    "            id=str(uuid.uuid4()),\n",
    "            text=summary,\n",
    "            level=context.get(\"level\", 1) if context else 1,\n",
    "            children_indices=context.get(\"children_indices\", []) if context else [],\n",
    "            metadata=context.get(\"metadata\", {})\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Session\n",
    "We connect to the existing database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = Path(\"tutorials/chunks.db\")\n",
    "if not db_path.exists():\n",
    "    print(\"Error: tutorials/chunks.db not found. Please run Tutorial 01 first.\")\n",
    "    # Creating dummy DB for standalone testing if needed\n",
    "    pass\n",
    "\n",
    "store = DiskChunkStore(db_path)\n",
    "config = ProcessingConfig(summarization_model=\"gpt-4o-mini\")\n",
    "\n",
    "# Initialize Engine\n",
    "agent = RefinementMockAgent(config, strategy=BaseSummaryStrategy())\n",
    "engine = InteractiveRaptorEngine(store=store, agent=agent, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select a Node\n",
    "We pick a Knowledge node (Level 1) to refine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Level 1 nodes\n",
    "knowledge_nodes = list(store.get_nodes_by_level(\"knowledge\"))\n",
    "\n",
    "if not knowledge_nodes:\n",
    "    # Fallback if 01_quickstart produced generic data level\n",
    "    # Or if mock agent produced DIKW metadata\n",
    "    # In 01_quickstart, LevelAwareMockAgent produced KNOWLEDGE nodes.\n",
    "    print(\"No KNOWLEDGE nodes found via metadata query. Fetching all summaries.\")\n",
    "    # This might happen if DiskChunkStore filtering is strict or metadata mismatch\n",
    "    # Let's just pick a random summary node that is NOT root\n",
    "    # But how to find them? Iterate all?\n",
    "    # For tutorial, we assume 01 worked.\n",
    "    pass\n",
    "\n",
    "if knowledge_nodes:\n",
    "    target_node = knowledge_nodes[0]\n",
    "    print(f\"Selected Node: {target_node.id}\")\n",
    "    print(f\"Original Text: {target_node.text}\")\n",
    "else:\n",
    "    print(\"Warning: Could not find Knowledge nodes. Creating a dummy one for demonstration.\")\n",
    "    from domain_models.data_schema import NodeMetadata, DIKWLevel\n",
    "    target_node = SummaryNode(\n",
    "        id=\"dummy-node\",\n",
    "        text=\"Original complex text.\",\n",
    "        level=1,\n",
    "        children_indices=[],\n",
    "        metadata=NodeMetadata(dikw_level=DIKWLevel.KNOWLEDGE)\n",
    "    )\n",
    "    store.add_summary(target_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Refine the Node\n",
    "We send an instruction to rewrite the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Explain this to a 5-year-old\"\n",
    "print(f\"Refining with instruction: '{instruction}'...\")\n",
    "\n",
    "updated_node = engine.refine_node(target_node.id, instruction)\n",
    "\n",
    "print(f\"\\nUpdated Text: {updated_node.text}\")\n",
    "print(f\"Refinement History: {updated_node.metadata.refinement_history}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trace Traceability\n",
    "We verify that we can still trace back to the original source chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_chunks = engine.get_source_chunks(updated_node.id)\n",
    "print(f\"\\nSource Chunks Found: {len(source_chunks)}\")\n",
    "\n",
    "if source_chunks:\n",
    "    print(f\"First Source Chunk: {source_chunks[0].text[:50]}...\")\n",
    "else:\n",
    "    print(\"No source chunks found (dummy node has no children).\")\n",
    "    \n",
    "store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}