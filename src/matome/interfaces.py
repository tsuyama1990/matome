from collections.abc import Iterable
from typing import Any, Protocol, runtime_checkable

from domain_models.config import ProcessingConfig
from domain_models.manifest import Chunk, Cluster


@runtime_checkable
class Chunker(Protocol):
    """
    Protocol for text chunking engines.

    Implementations are responsible for dividing large text documents into smaller,
    manageable segments (chunks) while preserving semantic meaning as much as possible.
    """

    def split_text(self, text: str, config: ProcessingConfig) -> Iterable[Chunk]:
        """
        Split text into chunks.

        This method should handle normalization, sentence splitting, and merging based on
        the configuration provided (e.g., max_tokens).

        Args:
            text: The full input text to be processed. If empty, should yield nothing.
            config: Configuration parameters including `max_tokens` and `overlap`.

        Yields:
            `Chunk` objects, each containing the chunk text and metadata.
            Yields nothing if the input text is empty.
        """
        ...


@runtime_checkable
class Clusterer(Protocol):
    """
    Protocol for clustering engines.

    Implementations should group similar text chunks or nodes based on their vector embeddings
    to facilitate hierarchical summarization (RAPTOR).
    """

    def cluster_nodes(
        self, embeddings: Iterable[list[float]], config: ProcessingConfig
    ) -> list[Cluster]:
        """
        Cluster nodes based on embeddings.

        This method identifies groups of similar nodes to be summarized together.

        Args:
            embeddings: An iterable of vectors (list of floats), where each vector corresponds to a node.
                        The order of embeddings implies the index (0..N-1).
            config: Configuration parameters such as `n_clusters` or `clustering_algorithm`.

        Returns:
            A list of `Cluster` objects.
            Each `Cluster` contains `node_indices` which correspond to the indices (0..N-1) of the
            input `embeddings` list.
        """
        ...


@runtime_checkable
class Summarizer(Protocol):
    """
    Protocol for summarization engines.

    Implementations should generate concise summaries of the provided text, respecting
    token limits and other configuration parameters.
    """

    def summarize(
        self,
        text: str | list[str],
        config: ProcessingConfig,
        strategy: "PromptStrategy | None" = None,
        context: dict[str, Any] | None = None,
    ) -> str:
        """
        Summarize the provided text.

        Args:
            text: The text to summarize. Can be a single string or a list of strings
                  (which will be joined or processed batch-wise).
            config: Configuration parameters such as `model_name` and `max_summary_tokens`.
            strategy: Optional summarization strategy to override default.
            context: Optional context dictionary for the strategy.

        Returns:
            The summary text generated by the model.
        """
        ...


@runtime_checkable
class PromptStrategy(Protocol):
    """
    Protocol for defining how to construct prompts and parse LLM outputs.
    Allows dynamic injection of summarization strategies (e.g., DIKW specific logic).
    """

    def format_prompt(self, text: str | list[str], context: dict[str, Any] | None = None) -> str:
        """
        Constructs the prompt string for the LLM.

        Args:
            text: The text to be summarized/processed. Can be a string or list of strings.
            context: Optional dictionary containing additional context (e.g., node level, instructions).

        Returns:
            The complete prompt string ready for the LLM.
        """
        ...

    def parse_output(self, response: str) -> dict[str, Any]:
        """
        Parses the raw string response from the LLM into a structured dictionary.

        Args:
            response: The raw text output from the LLM.

        Returns:
            A dictionary containing the parsed results (e.g., {"summary": "..."}).
        """
        ...
